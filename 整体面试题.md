# 操作系统

## 一 进程通信方法

每个进程各自有不同的用户地址空间,任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核,在内核中开辟一块缓冲区,进程A把数据从用户空间拷到内核缓冲区,进程B再从内核缓冲区把数据读走,内核提供的这种机制称为进程间通信。

### 1 匿名管道通信

------

匿名管道( pipe )：管道是一种**半双工**的通信方式，**数据只能单向流动**，而且只能在具**有亲缘关系的进程间**使用。进程的亲缘关系通常是指**父子进程关系**。

```vala
// 需要的头文件
#include <unistd.h>

// 通过pipe()函数来创建匿名管道
// 返回值：成功返回0，失败返回-1
// fd参数返回两个文件描述符
// fd[0]指向管道的读端，fd[1]指向管道的写端
// fd[1]的输出是fd[0]的输入。
int pipe (int fd[2]);
```

通过匿名管道实现进程间通信的步骤如下：

- 父进程创建管道，得到两个⽂件描述符指向管道的两端
- 父进程fork出子进程，⼦进程也有两个⽂件描述符指向同⼀管道。
- 父进程关闭fd[0],子进程关闭fd[1]，即⽗进程关闭管道读端,⼦进程关闭管道写端（因为管道只支持单向通信）。⽗进程可以往管道⾥写,⼦进程可以从管道⾥读,管道是⽤环形队列实现的,数据从写端流⼊从读端流出,这样就实现了进程间通信。



### 2 有名管道通信

------

有名管道 (named pipe) ： 有名管道也是**半双工**的通信方式，但是它**允许无亲缘关系进程间的通信**。



### 3 [消息队列](https://cloud.tencent.com/product/cmq?from=10680)通信

------

消息队列( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。



### 4 信号量通信

------

信号量( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

### 5 信号

------

信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

### 6 共享内存通信

------

共享内存( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。

### 7 套接字通信



## 二 孤儿进程僵尸进城

## 三 死锁条件，如何避免

## 四 哈希的实现有哪几种，如何取hashcode，冲突检测几种方法





# 计算机网络



## 一、time-wait的作用

## 二、http能不能一次连接多次请求，不等后端返回

## 三、TCP 有哪些状态

## 四、建立一个 socket 连接要经过哪些步骤

## 五  TCP 拥塞控制（快速恢复、快速重传）

## 六 https 握手，为什么需要 非对称加密 和 对称加密

## 七 io多路复用，epoll和select的区别

## 八   cookie session







# docker







# k8s



## 一、简述Kubernetes创建一个Pod的主要流程？

Kubernetes中创建一个Pod涉及多个组件之间联动，主要流程如下：

- 1、客户端提交Pod的配置信息（可以是yaml文件定义的信息）到kube-apiserver。
- 2、Apiserver收到指令后，通知给controller-manager创建一个资源对象。
- 3、Controller-manager通过api-server将pod的配置信息存储到ETCD数据中心中。
- 4、Kube-scheduler检测到pod信息会开始调度预选，会先过滤掉不符合Pod资源配置要求的节点，然后开始调度调优，主要是挑选出更适合运行pod的节点，然后将pod的资源配置单发送到node节点上的kubelet组件上。
- 5、Kubelet根据scheduler发来的资源配置单运行pod，运行成功后，将pod的运行信息返回给scheduler，scheduler将返回的pod运行状况的信息存储到etcd数据中心。



## Kubernetes中pod的创建流程

一般我们在创建pod的过程中都是，执行kubectl命令去apply对应的yaml文件，但是在执行这个操作的过程到pod被完成创建，k8s的组件都做了哪些操作呢？下面我们简要说说pod被创建的过程。

![image-20211011193626400](整体面试题.assets/image-20211011193626400.png)

1.用户通过kubectl命名发起请求。

2.apiserver通过对应的kubeconfig进行认证，认证通过后将yaml中的po信息存到etcd。

\3. Controller-Manager通过apiserver的watch接口发现了pod信息的更新，执行该资源所依赖的拓扑结构整合，整合后将对应的信息写到etcd，此时pod已经可以被调度了。

4.Scheduler同样通过apiserver的watch接口更新到pod可以被调度，通过算法给pod分配节点，并将pod和对应节点绑定的信息写到etcd，然后将pod交给kubelet。

5.kubelet收到pod后，调用CNI接口给pod创建pod网络，调用CRI接口去启动容器，调用CSI进行存储卷的挂载。

6.网络，容器，存储创建完成后pod创建完成，等业务进程启动后，pod运行成功。



## 二、k8s 核心组件

### **1.Master节点（默认不参加工作）**

```text
Kubectl：
 客户端命令行工具，作为整个K8s集群的操作入口；

Api Server：
 在K8s架构中承担的是“桥梁”的角色，作为资源操作的唯一入口，它提供了认证、授权、访问控制、API注册和发现等机制。客户端与k8s群集及K8s内部组件的通信，都要通过Api Server这个组件；

Controller-manager：
 负责维护群集的状态，比如故障检测、自动扩展、滚动更新等

Scheduler：
 负责资源的调度，按照预定的调度策略将pod调度到相应的node节点上；
```

> Etcd(可以不在master节点)：担任数据中心的角色，保存了整个群集的状态；

### **2.Node节点**

```text
Kubelet：
 负责维护容器的生命周期，同时也负责Volume和网络的管理，一般运行在所有的节点，是Node节点的代理，当Scheduler确定某个node上运行pod之后，会将pod的具体信息（image，volume）等发送给该节点的kubelet，kubelet根据这些信息创建和运行容器，并向master返回运行状态。（自动修复功能：如果某个节点中的容器宕机，它会尝试重启该容器，若重启无效，则会将该pod杀死，然后重新创建一个容器）；

Kube-proxy：
 Service在逻辑上代表了后端的多个pod。负责为Service提供cluster内部的服务发现和负载均衡（外界通过Service访问pod提供的服务时，Service接收到的请求后就是通过kube-proxy来转发到pod上的）；
 
container-runtime：
 是负责管理运行容器的软件，比如docker
```



## 三、etcd



## 四、controller 原理 和 operator 



## 五、网络互通

### 1. 同 node pod to pod

### 2. 不同 node pod to pod



## 六 怎么扩展 kubernetes scheduler, 让它能 handle 大规模的节点调度（蚂蚁金服面试题）



## 七 k8s 的 exec 是怎么实现的?（蚂蚁金服面试题）



## 八 有没有写过 k8s 的 Operator 或 Controller？（蚂蚁金服面试题）



## 九 对 Kubernetes 了解怎么样，看过源码吗？apiserver、scheduler、controller-manager

​            

## 十 谈一谈你对微服务架构的理解

微服务架构（MSA）的基础是将单个应用程序开发为一组小型独立服务，这些独立服务在自己的进程中运行，独立开发和部署。

**这些服务使用轻量级 API 通过明确定义的接口进行通信**。这些服务是围绕业务功能构建的，每项服务执行一项功能。由于它们是独立运行的，因此可以针对各项服务进行更新、部署和扩展，以满足对应用程序特定功能的需求。

### 微服务特性

- 自主性

**可以对微服务架构中的每个组件服务进行开发、部署、运营和扩展，而不影响其他服务的功能**。这些服务不需要与其他服务共享任何代码或实施。**各个组件之间的任何通信都是通过明确定义的 API 进行的。**

- 专用性

**每项服务都是针对一组功能而设计的，并专注于解决特定的问题**。如果开发人员逐渐将更多代码增加到一项服务中并且这项服务变得复杂，那么可以将其拆分成多项更小的服务。

### 微服务的优势

- 敏捷性

微服务促进若干小型独立团队形成一个组织，这些团队负责自己的服务。各团队在小型且易于理解的环境中行事，并且可以更独立、更快速地工作。**这缩短了开发周期时间**。您可以从组织的总吞吐量中显著获益。

- 扩展性

通过微服务，您可以独立扩展各项服务以满足其支持的应用程序功能的需求。这使团队能够适当调整基础设施需求，准确衡量功能成本，并在服务需求激增时保持可用性。

- 轻松部署

**微服务支持持续集成和持续交付，可以轻松尝试新想法，并可以在无法正常运行时回滚**。由于故障成本较低，因此可以大胆试验，更轻松地更新代码，并缩短新功能的上市时间。

- 代码可重用性

将软件划分为小型且明确定义的模块，让团队可以将功能用于多种目的。专为某项功能编写的服务可以用作另一项功能的构建块。这样应用程序就可以自行引导，因为开发人员可以创建新功能，而无需从头开始编写代码。

- 较好的弹性设计

服务独立性增加了应用程序应对故障的弹性。**在整体式架构中，如果一个组件出现故障，可能导致整个应用程序无法运行。通过微服务，应用程序可以通过降低功能而不导致整个应用程序崩溃来处理总体服务故障。**





## 十一 Informer 是怎么实现的，有什么作用？



1. **Reflector 通过ListWatcher 同步apiserver 数据（只启动时搞一次），并watch apiserver ，将event 加入到 Queue 中**
2. **controller 从 Queue中获取event，更新存储，并触发Processor 业务层注册的 ResourceEventHandler**

 

## 十二 Kubernetes 的所有资源约定了版本号, 为什么要这么做?

为了在兼容旧版本的同时不断升级新的 API，Kubernetes 支持多种 API 版本，不同的 API 版本代表其处于不同的稳定性阶段，低稳定性的 API 版本在后续的产品升级中可能成为高稳定性的版本。

为了简化删除字段或者重构资源表示等工作，Kubernetes 支持多个 API 版本， 每一个版本都在不同 API 路径下，例如 `/api/v1` 或 `/apis/rbac.authorization.k8s.io/v1alpha1`。



## 十三  raft算法是那种一致性算法







# go



## 1. goroutine 里面 panic 了会怎么样



在Go语言中，我们通常会用到panic和recover来抛出错误和捕获错误，这一对操作在单协程环境下我们正常用就好了，并不会踩到什么坑。但是在多协程并发环境下，我们常常会碰到以下两个问题。假设我们现在有2个协程，我们叫它们协程A和B好了：

- 如果协程A发生了panic，协程B是否会因为协程A的panic而挂掉？
- 如果协程A发生了panic，协程B是否能用recover捕获到协程A的panic？

答案分别是：会、不能。



**哪个协程发生了panic，我们就需要在哪个协程recover**



## 2. Go 中 defer 机制，可以返回数据吗

### defer概述

`defer` 是`golang` 中独有的流程控制语句，用于延迟指定语句的运行时机，只能运行于函数的内部，且当他所属函数运行完之后它才会被调用。例如：

```
func deferTest(){
    defer fmt.Println("HelloDefer")
    fmt.Println("HelloWorld")
}
```

它会先打印出`HelloWorld` ，然后再打印出`HelloDefer` 。

一个函数中如果有多个`defer` ，运行顺序和函数中的调用顺序相反，因为它们都是被写在了栈中：

```go
func deferTest(){
    defer fmt.Println("HelloDefer1")
    defer fmt.Println("HelloDefer2")
    fmt.Println("HelloWorld")
}
```

运行结果：

```go
fmt.Println("HelloDefer2")
fmt.Println("HelloDefer1")
fmt.Println("HelloWorld")
```

### defer和return

在包含有`return` 语句的函数中**，`defer` 的运行顺序位于`return` 之后，但是`defer` 所运行的代码片段会生效**：

```go
func main(){
    fmt.Println(deferReturn)
}
func deferReturn() int{
    i := 1
    defer func(){
        fmt.Println("Defer")
        i += 1
    }()
    return func()int{
        fmt.Println("Return")
        return i
    }()
}
```

运行结果：

```
Return
Defer
1
```

这里很明显就能看到`defer` 是在`return` 之后运行的！但是有一个问题是`defer` 里执行了语句`i +=1` ，按照这个逻辑的话返回的`i` 值应该是`2` 而不是`1` 。这个问题是由于`return` 的运行机制导致的：`return` 在返回一个对象时，如果返回类型不是指针或者引用类型，那么`return` 返回的就不会是这个对象本身，而是这个对象的副本。

我们可以验证这一个观点：

```go
func main(){
    ...
    fmt.Println("main:    ", x, &x)
}
func deferReturn() int{
    ...
    defer ...{
        fmt.Println("Defer:    ", i, &i)
        ...
    }()
    return ...{
        fmt.Println("Return:    ", i, &i)
        ...
    }()
}
```

程序的输出为：

```
Return:     1 0xc042008238
Defer:     1 0xc042008238
main:     1 0xc042008230  //main函数中的i的地址和deferReturn()中的i的地址是不一样的
```

如果把函数的返回值改成指针类型，这时候的main函数中的返回值就会和函数体内的一致：

```
func main(){
    x := deferReturn()
    fmt.Println("main:    ", x, *x)
}
func deferReturn()*int{
    i := 1
    p := &i
    defer func() {
        *p += 1
        fmt.Println("defer:    ", p, *p)
    }()
    return func() *int{
        fmt.Println("Return:    ", p, *p)
        return p
    }()
}
```

结果：

```
Return:     0xc0420361d0 1
defer:     0xc0420361d0 2
main:     0xc0420361d0 2
```

### defer与return的执行顺序

首先看个例子：

```go
package main

import (
    "fmt"
)

func main() {
    ret := test()
    fmt.Println("test return:", ret)
}

func test() ( int) {
    var i int

    defer func() {
        i++        //defer里面对i增1
        fmt.Println("test defer, i = ", i)
    }()

    return i
}
```

执行结果为：

```subunit
test defer, i =  1
test return: 0
```

test函数的返回值为0，defer里面的i++操作好像对返回值并没有什么影响。
这是否表示“return i”执行结束以后才执行defer呢？
非也！再看下面的例子：

```go
package main

import (
    "fmt"
)

func main() {
    ret := test()
    fmt.Println("test return:", ret)
}

//返回值改为命名返回值
func test() (i int) {
    //var i int

    defer func() {
        i++
        fmt.Println("test defer, i = ", i)
    }()

    return i
}
```

执行结果为：

```subunit
test defer, i =  1
test return: 1
```

这次test函数的返回值变成了1，defer里面的“i++"修改了返回值。所以defer的执行时机应该是return之后，且返回值返回给调用方之前。
至于第一个例子中test函数返回值不是1的原因，还涉及到函数匿名返回值与命名返回值的差异，以后再单独分析。

#### 结论

1. defer的执行顺序为：后defer的先执行。
2. :heavy_check_mark: **defer的执行顺序在return之后，但是在返回值返回给调用方之前，所以使用defer可以达到修改返回值的目的**。





## 3. go里面goroutine创建数量有限制吗？



- 有，P本地队列有数量限制，不允许超过 256 个
- 过多会占用大量的CPU和内存，并且会导致主进程奔溃





## 4. select可以用于什么

**在多个通道上进行读或写操作，让函数可以处理多个事情，但1次只处理1个。以下特性也都必须熟记于心：**

1. 每次执行select，都会只执行其中1个case或者执行default语句。
2. 当没有case或者default可以执行时，select则阻塞，等待直到有1个case可以执行。
3. 当有多个case可以执行时，则随机选择1个case执行。
4. `case`后面跟的必须是读或者写通道的操作，否则编译出错。



## 5. go map实现

#### sync.Map实现原理，适用的场景

这里会用另外一篇文章详细介绍



## 6. Go GC算法，三色标记法描述



## 7. Go内存模型(tcmalloc)



## 8. Go channel

- 在不能更改channel状态的情况下，没有简单普遍的方式来检查channel是否已经关闭了
- 关闭已经关闭的channel会导致panic，所以在closer(关闭者)不知道channel是否已经关闭的情况下去关闭channel是很危险的
- 发送值到已经关闭的channel会导致panic，所以如果sender(发送者)在不知道channel是否已经关闭的情况下去向channel发送值是很危险的



## 9. 判断 channel 是否已经被关闭

1. **从channel读取数据 ** (OK法) 

-  **第二个字段为true时，channel可能没关闭，也可能已经关闭，不能证明什么**
-  **第二个字段为false时，可以证明channel中已没有残留数据且已关闭**
-  **若channel已关闭 并且通道为空，那么从该channel中读取数据会直接返回，且是默认值，所以一定要判断第二个字段**

2. `for-range`是使用频率很高的结构，常用它来遍历数据，**`range`能够感知channel的关闭，当channel被发送数据的协程关闭时，range就会结束**，接着退出for循环。



## 10 关闭后的通道有以下特点：

1. 对一个关闭的通道再发送值就会导致panic。
2. **对一个关闭的通道进行接收会一直获取值直到通道为空**。
3. **对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。**
4. 关闭一个已经关闭的通道会导致panic。



## 11 go select介绍

A. select机制用来处理异步IO问题

B. select机制最大的一条限制就是每个case语句里必须是一个IO操作



## 12 map如何顺序读取



## 13 slice和array的区别

array是固定长度的数组，使用前必须确定数组长度

**array特点：**

- go的数组是**值类型**，也就是说一个数组赋值给另一个数组，那么实际上就是真个数组拷贝了一份，需要申请额外的内存空间
- 如果go中的数组做为函数的参数，那么**实际传递的参数是一份数组的拷贝**，而不是数组的指针
- array的**长度也是Type的一部分**，这样就说明[10]int和[20]int是不一样的

**slice特点：**

- slice是一个**引用类型**，是一个动态的指向数组切片的指针
- slice是一个不定长的，总是指向底层的数组array的数据结构

**区别：**

- 声明时：array需要声明长度或者...
- 做为函数参数时：**array传递的是数组的副本，slice传递的是指针**



## 14 channel 状态

**channel有三种状态：**

1. nil，未初始化的状态，只进行了声明，或者手动赋值为nil
2. active，正常的channel，可读可写
3. closed，已关闭

**channel可进行三种操作：**

1. 读
2. 写
3. 关闭

**这三种操作和状态可以组合出九种情况：**

| 操作               | nil的channel | 正常channel | 已关闭channel |
| ------------------ | ------------ | ----------- | ------------- |
| <-ch   (读)        | 阻塞         | 成功或阻塞  | 读到零值      |
| ch<-   (写)        | 阻塞         | 成功或阻塞  | panic         |
| close(ch)   (关闭) | panic        | 成功        | panic         |



## 15 在并发状态下map如何保证线程安全

go的map并发访问是不安全的，会出现未定义行为，导致程序退出。

go1.6之前，内置的map类型是部分goroutine安全的，并发的读没有问题，并发的写可能有问题。go1.6之后，并发的读写map会报错。

> 对比一下Java的`ConcurrentHashMap`的实现，在map的数据非常大的情况下，一把锁会导致大并发的客户端争抢一把锁，Java的解决方案是`shard`，内部使用多个锁，每个区间共享一把锁，这样减少了数据共享一把锁的性能影响

go1.9之前，一般情况下通过`sync.RWMutex`实现对map的并发访问控制，或者单独使用锁都可以。

go1.9之后，实现了`sync.Map`，类似于Java的`ConcurrentHashMap`。

`sync.Map`的实现有几个优化点：

1. 空间换时间。通过冗余的两个数据结构（read，dirty），实现加锁对性能的影响
2. 使用只读数据（read），避免读写冲突
3. 动态调整，miss次数多了之后，将dirty数据提升为read
4. double-checking
5. 延迟删除。删除一个键值只是打标记，只有在提升dirty的时候才清理删除的数据
6. 优先从read读取、更新、删除，因为对read的读取不需要锁



## 16 聊聊你对gc的理解

#### 内存管理

go实现的内存管理简单的说就是维护一块大的全局内存，每个线程（go中为P）维护一块小的私有内存，私有内存不足再从全局申请。

- go程序启动时申请一块大内存，并划分成spans、bitmap、arena区域
- arean区域按页划分成一个个小块
- span管理一个或多个页
- mcentral管理多个span供线程申请使用
- mcache作为线程私有资源，资源来源于mcentral

更多说明参阅引用说明[1](#fn-1)

#### 垃圾回收

常见的垃圾回收算法：

- 引用计数：对每个对象维护一个引用计数，当引用该对象的对象被销毁时，引用计数减一，当引用计数为0时回收该对象。
  - 优点：对象可以很快地被回收，不会出现内存耗尽或达到某个阈值时才回收。
  - 缺点：不能很好的处理循环引用，而且实时的维护引用计数，也有一定的代价。
  - 代表语言：Python、PHP、Swift
- 标记-清除：从根变量遍历所有引用的对象，引用对象标记为”被引用“，没有被标记的进行回收。
  - 优点：解决了引用计数的缺点
  - 缺点：需要STW（Stop The World），就是停掉所有的goroutine，专心做垃圾回收，待垃圾回收结束后再恢复goroutine，这回导致程序短时间的暂停。
  - 代表语言：Go（三色标记法）
- 分代收集：按照对象生命周期的长短划分不同的代空间，生命周期长的放入老年代，而短的放入新生代，不同代有不同的回收算法和回收频率。
  - 优点：回收性能好
  - 缺点：回收算法复杂
  - 代表语言：Java

##### Go垃圾回收的三色标记法

三色标记法只是为了描述方便抽象出来的一种说法，实际上对象并没有颜色之分。这里的三色对应了垃圾回收过程中对象的三种状态：

- 灰色：对象还在标记队列中等待
- 黑色：对象已被标记，gcmarkBits对应的位为1（对象不会在本次GC中被清理）
- 白色：对象未被标记，gcmarkBits对应的位为0（对象将会在本次GC中被清理）

#### 垃圾回收优化[2](#fn-2)

##### 写屏障（Write Barrier）

前面说过STW目的是防止GC扫描时内存变化而停掉goroutine，而写屏障就是让goroutine与GC同时运行的手段。虽然写屏障不能完全消除STW，但是可以大大减少STW的时间。

写屏障类似一种开关，在GC的特定时机开启，开启后指针传递时会把指针标记，即本轮不回收，下次GC时再确定。

GC过程中新分配的内存会被立即标记，用的并不是写屏障技术，也即GC过程中分配的内存不会在本轮GC中回收。

##### 辅助GC（Mutator Assist）

为了防止内存分配过快，在GC执行过程中，如果goroutine需要分配内存，那么这个goroutine会参与一部分GC的工作，即帮助GC做一部分的工作，这个机制叫做Mutator Assist。

#### 垃圾回收触发时机[3](#fn-3)

##### 内存分配量达到阈值出发GC

每次内存分配时都会检查当前内存分配量是否已达到阈值，如果达到阈值则立即启动GC。

```
阈值 = 上次GC内存分配量 * 内存增长率
复制代码
```

内存增长率由环境变量`GOGC`控制，默认为100，即每当内存扩大一倍时启动GC。

##### 定期触发GC

默认情况下，最长2分钟触发一次GC，这个间隔在`src/runtime/proc.go:forcegcperiod`变量中被声明：

```go
// forcegcperiod is the maximum time in nanoseconds between garbage
// collections. If we go this long without a garbage collection, one
// is forced to run.
//
// This is a variable for testing purposes. It normally doesn't change.
var forcegcperiod int64 = 2 * 60 * 1e9
复制代码
```

##### 手动触发

程序代码中也可以使用`runtime.GC()`来手动触发GC，这主要用于GC性能测试和统计。

#### GC性能优化

GC性能与对象数量负相关，对象越多GC性能越差，对程序影响越大。

所以GC性能优化的思路之一就是减少对象分配个数，比如对象复用或使用大对象组合多个小对象等等。

另外，由于*内存逃逸现象*，有些隐式的内存分配也会产生，也有可能成为GC的负担。

> 内存逃逸现象[3.1](#fn-3.1)：变量分配在栈上需要能在编译器确定它的作用域，否则就会被分配到堆上。而堆上动态分配内存比栈上静态分配内存，开销大很多。

go通过`go build -gcflags=m`命令来观察变量逃逸情况[4](#fn-4)

更多逃逸场景：[逃逸场景](https://link.juejin.cn?target=https%3A%2F%2Frainbowmango.gitbook.io%2Fgo%2Fchapter04%2F4.3-escape_analysis%233-tao-yi-chang-jing)

**逃逸分析的作用：**

1. 逃逸分析的好处是为了减少GC的压力，不逃逸的对象分配在栈上，当函数返回时就回收了资源，不需要GC标记清除。
2. 逃逸分析完后可以确定哪些变量可以分配在栈上，栈的分配比堆快，性能好（逃逸的局部变量会分配在堆上，而没有发生逃逸的则由编译器分配到栈上）
3. 同步消除，如果你定义的对象在方法上有同步锁，但在运行时，却只有一个线程在访问，此时逃逸分析后的机器码，会去掉同步锁运行

**逃逸总结**

- 栈上分配内存比在堆中分配内存有更高的效率
- 栈上分配的内存不需要GC处理
- 堆上分配的内存使用完毕会交给GC处理
- 逃逸分析的目的是决定内存分配到堆还是栈
- 逃逸分析在编译阶段完成



## 17 GMP 模型，为什么要有 P？

其实这个面试题本质是想问：”**GMP 模型，为什么不是 G 和 M 直接绑定就完了，还要搞多一个 P 出来，那么麻烦，为的是什么，是要解决什么问题吗**？“



### 解密 Go1.0 源码

```c++
static void
schedule(G *gp)
{
	...
	schedlock();                 // 获取全局锁
	if(gp != nil) {
		...
		switch(gp->status){
		case Grunnable:
		case Gdead:
			// Shouldn't have been running!
			runtime·throw("bad gp->status in sched");
		case Grunning:      // 当前 Goroutine 状态从 Running（正在被调度） 状态修改为 Runnable（可以被调度）状态
			gp->status = Grunnable;
			gput(gp);   // 保存当前 Goroutine 的运行状态等信息
			break;
		}

	gp = nextgandunlock();    // 寻找下一个可运行 Goroutine, 释放全局锁给其他调度使用
	gp->readyonstop = 0;
	gp->status = Grunning;
	m->curg = gp;
	gp->m = m;
	...
	runtime·gogo(&gp->sched, 0);   // 将刚刚所获取到的下一个待执行的 Goroutine 运行起来
}

```

- 调用 `schedlock` 方法来获取全局锁。
- 获取全局锁成功后，将当前 Goroutine 状态从 Running（正在被调度） 状态修改为 Runnable（可以被调度）状态。
- 调用 `gput` 方法来保存当前 Goroutine 的运行状态等信息，以便于后续的使用；
- 调用 `nextgandunlock` 方法来寻找下一个可运行 Goroutine，并且释放全局锁给其他调度使用。
- 获取到下一个待运行的 Goroutine 后，将其的运行状态修改为 Running。
- 调用 `runtime·gogo` 方法，将刚刚所获取到的下一个待执行的 Goroutine 运行起来。



我们可以发现一个比较有趣的点。那就是调度器本身（schedule 方法），在正常流程下，是不会返回的，也就是不会结束主流程。

![G-M模型简图](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2bf2b9ea4008477f80152749420f8c08~tplv-k3u1fbpfcp-watermark.awebp)

他会不断地运行调度流程，GoroutineA 完成了，就开始寻找 GoroutineB，寻找到 B 了，就把已经完成的 A 的调度权交给 B，让 GoroutineB 开始被调度，也就是运行。

当然了，也有被正在阻塞（Blocked）的 G。假设 G 正在做一些系统、网络调用，那么就会导致 G 停滞。这时候 M（系统线程）就会被会重新放内核队列中，等待新的一轮唤醒。



### GM 模型的缺点

当前（代指 Go1.0 的 GM 模型）的 Goroutine 调度器限制了用 Go 编写的并发程序的可扩展性，尤其是高吞吐量服务器和并行计算程序。

实现有如下的问题：

- **存在单一的全局 mutex（Sched.Lock）和集中状态管理**：
  - mutex 需要保护所有与 goroutine 相关的操作（创建、完成、重排等），**导致锁竞争严重。**
- Goroutine 传递的问题：
  - goroutine（G）交接（G.nextg）：工作者线程（M's）之间会经常交接可运行的 goroutine。
  - 上述可能会导致延迟增加和额外的开销。每个 M 必须能够执行任何可运行的 G，特别是刚刚创建 G 的 M。
- 每个 M 都需要做内存缓存（M.mcache）：
  - 会导致资源消耗过大（每个 mcache 可以吸纳到 2M 的内存缓存和其他缓存），数据局部性差。
- 频繁的线程阻塞/解阻塞：
  - 在存在 syscalls 的情况下，线程经常被阻塞和解阻塞。这增加了很多额外的性能开销。

## GMP 模型

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a5ecbea79fa243678475e9fae7168365~tplv-k3u1fbpfcp-watermark.awebp)

### 带来什么改变 (面试的时候可以回答这部分)

加了 P 之后会带来什么改变呢？我们再更显式的讲一下。

- **每个 P 有自己的本地队列**，大幅度的减轻了对**全局队列**的直接依赖，**所带来的效果就是锁竞争的减少**。而 GM 模型的性能开销大头就是锁竞争。
- **每个 P 相对的平衡上**，在 GMP 模型中也实现了 **Work Stealing 算法**，如果 P 的本地队列为空，则会从全局队列或其他 P 的本地队列中窃取可运行的 G 来运行，**减少空转，提高了资源利用率**。

### 为什么要有 P

这时候就有小伙伴会疑惑了，如果是想实现本地队列、Work Stealing 算法，那为什么不直接在 M 上加呢，M 也照样可以实现类似的组件。为什么又再加多一个 P 组件？

结合 M（系统线程） 的定位来看，若这么做，有以下问题：

- 一般来讲，M 的数量都会多于 P。**像在 Go 中，M 的数量默认是 10000，P 的默认数量的 CPU 核数**。另外由于 M 的属性，也就是如果存在系统阻塞调用，阻塞了 M，又不够用的情况下，M 会不断增加。
- M 不断增加的话，如果本地队列挂载在 M 上，那就意味着本地队列也会随之增加。这显然是不合理的，**因为本地队列的管理会变得复杂**，且 Work Stealing 性能会大幅度下降。
- M 被系统调用阻塞后，我们是期望把他既有未执行的任务分配给其他继续运行的，而不是一阻塞就导致全部停止。

因此使用 M 是不合理的，那么引入新的组件 P，把本地队列关联到 P 上，就能很好的解决这个问题。





## 18  new make 区别

本质上在于 `make` 函数在初始化时，会初始化 `slice`、`chan`、`map` 类型的内部数据结构，`new` 函数并不会。

例如：在 `map` 类型中，合理的长度（len）和容量（cap）可以提高效率和减少开销。

更进一步的区别：

- ```
  make
  ```

  - 能够创建类型所需的内存空间，返回引用类型的本身。
  - 具有使用范围的局限性，仅支持 `channel`、`map`、`slice` 三种类型。
  - 具有独特的优势，`make` 函数会对三种类型的内部数据结构（长度、容量等）赋值。

- ```
  new
  ```

  - 能够创建并分配类型所需的内存空间，返回指针引用（指向内存的指针）。
  - 可被替代，能够通过字面值快速初始化。



## 19 Goroutine 数量控制在多少合适，会影响 GC 和调度？



## 20 两个 interface 可以比较吗？



## 21 局部变量在堆空间还是栈空间



## 22 什么是协程泄露



## 23 Golang 里的逃逸分析是什么？怎么避免内存逃逸？



## 24 goroutine 和 kernel thread 之间什么关系



## 25 go 内存逃逸分析（分析了栈帧，讲五种例子，描述堆栈优缺点，点头）



## 26 defer recover 的问题



## 27 select可以用于什么？







# gin



### 聊聊你对gin的理解

gin是一个go的微框架，封装优雅，API友好。快速灵活。容错方便等特点。

其实对于go而言，对web框架的依赖远比Python、Java之类的小。本身的`net/http`足够简单，而且性能也非常不错，大部分的框架都是对`net/http`的高阶封装。所以gin框架更像是一些常用函数或者工具的集合。使用gin框架发开发，可以提升效率，并同意团队的编码风格。

### gin的路由组件为什么高性能

#### 路由树

gin使用高性能路由库`httprouter`[5](#fn-5)

在Gin框架中，路由规则被分成了9课前缀树，每一个HTTP Method对应一颗前缀树，树的节点按照URL中的 / 符号进行层级划分

#### gin.RouterGroup

RouterGroup是对路由树的包装，所有的路由规则最终都是由它来进行管理。Engine结构体继承了RouterGroup，所以Engine直接具备了RouterGroup所有的路由管理功能。

### gin数据绑定

gin提供了很方便的数据绑定功能，**可以将用户传过来的参数自动跟我们定义的结构体绑定在一起。**

这是也我选择用gin的重要原因。

### gin数据验证

在上面数据绑定的基础上，gin还提供了数据校验的方法。gin的数据验证是和数据绑定结合在一起的。只需要在数据绑定的结构体成员变量的标签添加`binding`规则即可。这又省了大量的验证工作，对用惯AspCoreMVC、Spring MVC的程序员来说是完美的替代框架。

### gin的中间件

gin中间件利用函数调用栈`后进先出`的特点，完成中间件在自定义处理函数完成后的处理操作。



# 数据库



## 事务

## 索引

## 事务是怎么实现的?



# istio

